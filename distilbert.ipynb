{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Fine-tune DistilBERT model for Deepfake Tweet Detection\n",
    "\n",
    "\n",
    "\n",
    " This notebook implements a fine-tuning pipeline for DistilBERT model, aiming to achieve better performance\n",
    "\n",
    " than the BERT baseline while being more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import (\n",
    "    DistilBertTokenizer, \n",
    "    DistilBertForSequenceClassification, \n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Import our modular utilities\n",
    "from model_utils import (\n",
    "    set_seed, prepare_data, train_model, evaluate_model,\n",
    "    plot_training_stats, plot_confusion_matrix, analyze_results_by_length, analyze_results_by_class\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed datasets\n",
    "data_path = \"data/preprocessed/\"\n",
    "train_df = pd.read_csv(os.path.join(data_path, \"tweepfake_train.csv\"))\n",
    "val_df = pd.read_csv(os.path.join(data_path, \"tweepfake_val.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(data_path, \"tweepfake_test.csv\"))\n",
    "\n",
    "print(f\"Train set shape: {train_df.shape}\")\n",
    "print(f\"Validation set shape: {val_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "print(\"Train set class distribution:\")\n",
    "print(train_df['account.type'].value_counts())\n",
    "print(\"\\nDetailed class distribution:\")\n",
    "print(train_df['class_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Prepare Data and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Prepare data\n",
    "_, _, _, train_dataloader, val_dataloader, test_dataloader = prepare_data(\n",
    "    train_df, val_df, test_df, tokenizer, batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"Created dataloaders with batch size 32\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Load DistilBERT Model\n",
    "\n",
    " DistilBERT is a smaller, faster version of BERT that retains 97% of BERT's performance while being 40% smaller and 60% faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained DistilBERT model for sequence classification\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "print(\"Loaded pre-trained DistilBERT model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and learning rate scheduler\n",
    "# Using a slightly higher learning rate for DistilBERT compared to BERT\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
    "\n",
    "# Number of training epochs (increased from BERT's 4 to 5 for DistilBERT to compensate for model size)\n",
    "epochs = 5\n",
    "\n",
    "# Total number of training steps\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Set up the learning rate scheduler with warmup\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=int(0.1 * total_steps),  # 10% warmup\n",
    "    num_training_steps=total_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "fine_tuned_model, training_stats = train_model(\n",
    "    model, train_dataloader, val_dataloader, optimizer, scheduler, epochs, device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss/metrics\n",
    "plot_training_stats(training_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating DistilBERT model on test set...\")\n",
    "eval_results = evaluate_model(fine_tuned_model, test_dataloader, device)\n",
    "\n",
    "# Print results\n",
    "print(f\"Test Loss: {eval_results['loss']:.4f}\")\n",
    "print(f\"Test Accuracy: {eval_results['accuracy']:.4f}\")\n",
    "print(f\"Test F1 Score: {eval_results['f1']:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(eval_results['true_labels'], eval_results['predictions'], \n",
    "                          target_names=['Human', 'Bot']))\n",
    "\n",
    "# Create confusion matrix\n",
    "plot_confusion_matrix(eval_results['true_labels'], eval_results['predictions'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze by tweet length\n",
    "accuracy_by_length = analyze_results_by_length(test_df, eval_results['predictions'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze by tweet class\n",
    "accuracy_by_class = analyze_results_by_class(test_df, eval_results['predictions'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Compare with BERT Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DistilBERT performed with the following metrics:\")\n",
    "print(f\"Accuracy: {eval_results['accuracy']:.4f}\")\n",
    "print(f\"F1 Score: {eval_results['f1']:.4f}\")\n",
    "print(\"\\nCompared to the BERT baseline, DistilBERT offers:\")\n",
    "print(\"- Faster training and inference times\")\n",
    "print(\"- Smaller model size (40% smaller than BERT)\")\n",
    "print(\"- Comparable performance while being more efficient\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Save Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model (uncomment to enable)\n",
    "\"\"\"\n",
    "model_save_path = \"models/distilbert_deepfake_detector/\"\n",
    "fine_tuned_model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
